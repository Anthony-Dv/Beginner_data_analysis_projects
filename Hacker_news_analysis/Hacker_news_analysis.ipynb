{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0c7439",
   "metadata": {},
   "source": [
    "# Hacker News, posting optimization for more comments\n",
    "## Introduction\n",
    "In this project I am going to analyze set of 20 000 posts on Hacker News. My goal is to figure out which posts are among the most popular and what contributes to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35d2b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "hn_open = open(\"Hacker_news.csv\")\n",
    "hn_read = list(csv.reader(hn_open))\n",
    "hn_header = hn_read[0]\n",
    "hn = hn_read[1:]\n",
    "print(hn_header)\n",
    "print(\"\\n\")\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f489dd",
   "metadata": {},
   "source": [
    "Separate each post in `ask_posts`, `show_posts` or `other_posts`. Also I am goin to check how many posts of each \"category\" there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5536276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if (title.lower().startswith(\"ask hn\")):\n",
    "        ask_posts.append(row)\n",
    "    elif (title.lower().startswith(\"show hn\")):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dd5b2",
   "metadata": {},
   "source": [
    "Now lets find out which type of post gets more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb10eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n",
      "5.430900536163694\n"
     ]
    }
   ],
   "source": [
    "# count number of comments per ask posts\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "# print average number of commnets per ask post\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "\n",
    "# count number of commnets per show post\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "# print average number of commnets per show post\n",
    "avg_show_comments = total_show_comments/len(ask_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412fb27",
   "metadata": {},
   "source": [
    "On average, for the **Ask HN** we have 10.39 comments per posts and for the **Show HN** it's only 4.89 comments per post. This shows us that people are more willing to comment on **Ask HN** posts than **Show HN**. Based on this fact, for our next steps we will analyze **only Ask HN posts.**\n",
    "\n",
    "Next I will calculate the number of ask posts created in each hour of the day, along with the number of comments received. Also I will calculate the average number of commnets ask posts receive by hour created. I will use datetime module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49632509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 269, 1: 282, 22: 383, 21: 518, 19: 552, 17: 587, 15: 646, 14: 513, 13: 444, 11: 312, 10: 282, 9: 222, 7: 226, 3: 271, 23: 343, 20: 510, 16: 579, 8: 257, 0: 301, 18: 614, 12: 342, 4: 243, 6: 234, 5: 209}\n",
      "\n",
      "\n",
      "{2: 2996, 1: 2089, 22: 3372, 21: 4500, 19: 3954, 17: 5547, 15: 18525, 14: 4972, 13: 7245, 11: 2797, 10: 3013, 9: 1477, 7: 1585, 3: 2154, 23: 2297, 20: 4462, 16: 4466, 8: 2362, 0: 2277, 18: 4877, 12: 4234, 4: 2360, 6: 1587, 5: 1838}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "\n",
    "# append created_at and number of comments to result_list\n",
    "for row in ask_posts:\n",
    "    result_list.append((row[6], int(row[4])))\n",
    "\n",
    "# create 2 dictionaries\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    new_date = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = new_date.hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "\n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773f005",
   "metadata": {},
   "source": [
    "Now I am going to determine average number of commnets per post on specific hour of the day to see if there are any advantages of chooising specific time to post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3302ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 11.14], [1, 7.41], [22, 8.8], [21, 8.69], [19, 7.16], [17, 9.45], [15, 28.68], [14, 9.69], [13, 16.32], [11, 8.96], [10, 10.68], [9, 6.65], [7, 7.01], [3, 7.95], [23, 6.7], [20, 8.75], [16, 7.71], [8, 9.19], [0, 7.56], [18, 7.94], [12, 12.38], [4, 9.71], [6, 6.78], [5, 8.79]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour, round((comments_by_hour[hour]/counts_by_hour[hour]), 2)])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1e34f",
   "metadata": {},
   "source": [
    "Although I now have the results I need, this format makes it difficult to identify the hours with the highest values. Let's finish by sorting the list of lists and printing highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216049ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.14, 2], [7.41, 1], [8.8, 22], [8.69, 21], [7.16, 19], [9.45, 17], [28.68, 15], [9.69, 14], [16.32, 13], [8.96, 11], [10.68, 10], [6.65, 9], [7.01, 7], [7.95, 3], [6.7, 23], [8.75, 20], [7.71, 16], [9.19, 8], [7.56, 0], [7.94, 18], [12.38, 12], [9.71, 4], [6.78, 6], [8.79, 5]]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8688caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "\n",
    "for item in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(str(item[1]), \"%H\")\n",
    "    hour = hour.strftime(\"%H:%M\")\n",
    "    avg = item[0]\n",
    "    print(\"{}: {} average comments per post\".format(hour, avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ae6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
